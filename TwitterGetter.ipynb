{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Getter\n",
    "**This notebook illustrates three different methods of requesting Twitter data**\n",
    "1. Using OAuth2 to pull data from Twitter's standard search API in JSON format\n",
    "2. Using Tweepy to pull data from Twitter's standard search API into a SQLite database\n",
    "3. Using Tweepy to pull live data from Twitter's streaming API in JSON format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before getting started, generate the necessary keys and access tokens\n",
    "You are going to need to create a Twitter account and generate your own keys on [apps.twitter.com](apps.twitter.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After generating your keys, add them here\n",
    "# You will not be able to connect to Twitter's API without them\n",
    "\n",
    "API_KEY = 'INSERT YOUR KEY HERE'\n",
    "API_SECRET = 'INSERT YOUR KEY HERE'\n",
    "TOKEN_KEY = 'INSERT YOUR KEY HERE'\n",
    "TOKEN_SECRET = 'INSERT YOUR KEY HERE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using OAuth2 to pull data from Twitter's standard search API in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import oauth2\n",
    "import json\n",
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "# oauth_req accepts the url of the API endpoint, TOKEN_KEY, and TOKEN_SECRET and returns the requested content\n",
    "def oauth_req(url, key, secret, http_method=\"GET\", post_body=b\"\", http_headers=None):\n",
    "    consumer = oauth2.Consumer(key=API_KEY, secret=API_SECRET)\n",
    "    token = oauth2.Token(key=key, secret=secret)\n",
    "    client = oauth2.Client(consumer, token)\n",
    "    resp, content = client.request(url, method=http_method, body=post_body, headers=http_headers)\n",
    "    return content\n",
    "\n",
    "search = \"INSERT YOUR SEARCH TERM(S) HERE\" # put your search term(s) inside the quotes before running this cell\n",
    "\n",
    "search_endpoint = 'https://api.twitter.com/1.1/search/tweets.json?q='\n",
    "formatted_search = urllib.parse.quote(search, safe='')\n",
    "url = search_endpoint + formatted_search + '&lang=en&result_type=popular&tweet_mode=extended'\n",
    "data = oauth_req(url, TOKEN_KEY, TOKEN_SECRET)\n",
    "\n",
    "# writing the retrieved data to a JSON file\n",
    "with open('tweet_data.json', 'wb') as data_file: \n",
    "    data_file.write(data)\n",
    "    \n",
    "# loading the JSON data to make sure there was nothing wrong with the file we just created\n",
    "open_json = open('tweet_data.json').read()\n",
    "json_data = json.loads(open_json)\n",
    "\n",
    "# create a Pandas dataframe from the JSON for easier examination and manipulation\n",
    "tweetDF = pd.DataFrame(json_data['statuses'])\n",
    "\n",
    "# take a peek at the dataframe\n",
    "tweetDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the username and full text of the Tweets we just collected\n",
    "Twitter's standard search API defaults to a maximum of 15 records per query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tweetDF.full_text)):\n",
    "    print(\"@\" + tweetDF.user[i]['screen_name'] + \" - \" + tweetDF.full_text[i] + \"\\n____________________\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using Tweepy to pull data from Twitter's standard search API into a SQLite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "import tweepy\n",
    "import sqlite3\n",
    "\n",
    "# store_tweet connects to SQLite, creates a table called \"tweets\" if it doesn't already exist, \n",
    "# and inserts newly gathered data into the table\n",
    "def store_tweet(item):\n",
    "    db = dataset.connect('sqlite:///newTweets.db')\n",
    "    table = db.create_table('tweets', primary_id=False)\n",
    "    item_json = item._json.copy()\n",
    "    for k, v in item_json.items():\n",
    "        if isinstance(v, dict):\n",
    "            item_json[k] = str(v)\n",
    "    table.insert(item_json)\n",
    "    \n",
    "\n",
    "auth = tweepy.AppAuthHandler(API_KEY, API_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "query = 'INSERT YOUR SEARCH TERM(S) HERE' # put your search term(s) inside the quotes before running this cell\n",
    "\n",
    "# executing the query with specified settings\n",
    "cursor = tweepy.Cursor(api.search, q=query, lang='en', result_type='popular')\n",
    "\n",
    "# iterating through 5 pages of records to add each record to our database\n",
    "for page in cursor.pages(5):\n",
    "    for item in page:\n",
    "        store_tweet(item)\n",
    "\n",
    "# use SQLite3 to connect to the database we just put data into\n",
    "conn = sqlite3.connect('newTweets.db')\n",
    "\n",
    "# create a Pandas dataframe from a SQL query of our newTweets database\n",
    "tweepyDF = pd.read_sql_query('SELECT * FROM tweets LIMIT 15;', conn)\n",
    "\n",
    "# take a peek at the dataframe\n",
    "tweepyDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the username and text from first 15 Tweets in our new database\n",
    "Our SQL query had a limit of 15, so tweepyDF only contains 15 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'user' column looks like a dictionary, but is formatted as a string\n",
    "# I converted it to a dictionary to access the user's screen name\n",
    "\n",
    "tweepyDF.user = tweepyDF.user.map(lambda x: dict(eval(x)))\n",
    "\n",
    "for i in range(15):\n",
    "    print(\"@\" + tweepyDF.user[i]['screen_name'] + \" - \" + tweepyDF.text[i] + \"\\n____________________\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Tweepy to pull live data from Twitter's streaming API in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener \n",
    "from tweepy import OAuthHandler, Stream\n",
    "import time\n",
    "\n",
    "class Listener(StreamListener):\n",
    "    # Setting a timer for 60 seconds and creating tweetStream.json if it doesn't already exist\n",
    "    # \n",
    "    def __init__(self, time_limit=60):\n",
    "        self.start_time = time.time()\n",
    "        self.limit = time_limit\n",
    "        self.saveFile = open('tweetStream.json', 'a')\n",
    "\n",
    "    # makes sure the timer hasn't expired before continuing to write data\n",
    "    def on_data(self, data):\n",
    "        if (time.time() - self.start_time) < self.limit:\n",
    "            self.saveFile.write(data)\n",
    "            return True\n",
    "        else:\n",
    "            self.saveFile.close()\n",
    "            return False\n",
    "        \n",
    "auth = OAuthHandler(API_KEY, API_SECRET)\n",
    "auth.set_access_token(TOKEN_KEY, TOKEN_SECRET)\n",
    "\n",
    "stream = Stream(auth, Listener()) # starting up the stream\n",
    "stream.filter(track=['Warzone']) # telling the stream what to track\n",
    "\n",
    "# load the data we just collected into tweets_data\n",
    "tweets_data = []\n",
    "with open('tweetStream.json', 'r') as tweets_file:\n",
    "    for line in tweets_file:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "\n",
    "# turn tweets_data into a pandas dataframe and take a peek at the results\n",
    "streamDF = pd.DataFrame(tweets_data)\n",
    "streamDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the username and text from the first 15 streaming Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print(\"@\" + streamDF.user[i]['screen_name'] + \" - \" + streamDF.text[i] + \"\\n____________________\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
